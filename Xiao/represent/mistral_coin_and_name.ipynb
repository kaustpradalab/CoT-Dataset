{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/CV/anaconda3/envs/llm_ref2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from repeng import ControlVector, ControlModel, DatasetEntry\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"/root/autodl-tmp/.catch/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = 0\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "model = model.to(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ControlModel(model, list(range(-5, -18, -1)))\n",
    "user_tag, asst_tag = \"[INST]\", \"[/INST]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>num</th>\n",
       "      <th>ordinal_index</th>\n",
       "      <th>class</th>\n",
       "      <th>explain</th>\n",
       "      <th>Content</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MC</td>\n",
       "      <td>0</td>\n",
       "      <td>first</td>\n",
       "      <td>Method is wrong</td>\n",
       "      <td>Because the prediction incorrectly identifies ...</td>\n",
       "      <td>Morgan Calderon</td>\n",
       "      <td>The first letter of each word in \"Morgan Calde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rr</td>\n",
       "      <td>2</td>\n",
       "      <td>third</td>\n",
       "      <td>Method is wrong</td>\n",
       "      <td>Because the prediction misunderstands the ques...</td>\n",
       "      <td>Mervin Carroll</td>\n",
       "      <td>The third letter of each word in Mervin Carrol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ec</td>\n",
       "      <td>1</td>\n",
       "      <td>second</td>\n",
       "      <td>Method is wrong</td>\n",
       "      <td>Because the prediction incorrectly identifies ...</td>\n",
       "      <td>Bert Schwartz</td>\n",
       "      <td>The second letters of the words in Bert Schwar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JKPR</td>\n",
       "      <td>0</td>\n",
       "      <td>first</td>\n",
       "      <td>Method correct but process wrong</td>\n",
       "      <td>Because the method of taking the first letters...</td>\n",
       "      <td>Jonathon Kelly Parra Rosas</td>\n",
       "      <td>J K P R R are the first letters of each word i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raln</td>\n",
       "      <td>2</td>\n",
       "      <td>third</td>\n",
       "      <td>Method is wrong</td>\n",
       "      <td>Because the prediction incorrectly interprets ...</td>\n",
       "      <td>Darren Diaz Ellis Conner</td>\n",
       "      <td>To find the answer, follow these steps:\\n\\n1. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>ezal</td>\n",
       "      <td>2</td>\n",
       "      <td>third</td>\n",
       "      <td>Method correct but process wrong</td>\n",
       "      <td>Because the prediction correctly identifies th...</td>\n",
       "      <td>Drew Vazquez Chase Keller</td>\n",
       "      <td>The third letter of each word in Drew Vazquez ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>tiol</td>\n",
       "      <td>3</td>\n",
       "      <td>fourth</td>\n",
       "      <td>Method correct but process wrong</td>\n",
       "      <td>Because the method described in the prediction...</td>\n",
       "      <td>Weston Hamilton Lugo Arellano</td>\n",
       "      <td>To find the answer, follow these steps:\\n\\n1. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>uh</td>\n",
       "      <td>3</td>\n",
       "      <td>fourth</td>\n",
       "      <td>Method is wrong</td>\n",
       "      <td>Because the prediction correctly identifies an...</td>\n",
       "      <td>August Archer</td>\n",
       "      <td>The fourth letter of the word \"August\" is \"g\"....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>aa</td>\n",
       "      <td>1</td>\n",
       "      <td>second</td>\n",
       "      <td>Method is wrong</td>\n",
       "      <td>Because the prediction incorrectly describes t...</td>\n",
       "      <td>Marlin Garza</td>\n",
       "      <td>The second letters of the words \"Marlin\" and \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>LS</td>\n",
       "      <td>0</td>\n",
       "      <td>first</td>\n",
       "      <td>Totally correct</td>\n",
       "      <td>Because the prediction correctly identifies th...</td>\n",
       "      <td>Leslie Sellers</td>\n",
       "      <td>The first letter of each word in Leslie Seller...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    label  num ordinal_index                             class  \\\n",
       "0      MC    0         first                   Method is wrong   \n",
       "1      rr    2         third                   Method is wrong   \n",
       "2      ec    1        second                   Method is wrong   \n",
       "3    JKPR    0         first  Method correct but process wrong   \n",
       "4    raln    2         third                   Method is wrong   \n",
       "..    ...  ...           ...                               ...   \n",
       "195  ezal    2         third  Method correct but process wrong   \n",
       "196  tiol    3        fourth  Method correct but process wrong   \n",
       "197    uh    3        fourth                   Method is wrong   \n",
       "198    aa    1        second                   Method is wrong   \n",
       "199    LS    0         first                   Totally correct   \n",
       "\n",
       "                                               explain  \\\n",
       "0    Because the prediction incorrectly identifies ...   \n",
       "1    Because the prediction misunderstands the ques...   \n",
       "2    Because the prediction incorrectly identifies ...   \n",
       "3    Because the method of taking the first letters...   \n",
       "4    Because the prediction incorrectly interprets ...   \n",
       "..                                                 ...   \n",
       "195  Because the prediction correctly identifies th...   \n",
       "196  Because the method described in the prediction...   \n",
       "197  Because the prediction correctly identifies an...   \n",
       "198  Because the prediction incorrectly describes t...   \n",
       "199  Because the prediction correctly identifies th...   \n",
       "\n",
       "                           Content  \\\n",
       "0                  Morgan Calderon   \n",
       "1                   Mervin Carroll   \n",
       "2                    Bert Schwartz   \n",
       "3       Jonathon Kelly Parra Rosas   \n",
       "4         Darren Diaz Ellis Conner   \n",
       "..                             ...   \n",
       "195      Drew Vazquez Chase Keller   \n",
       "196  Weston Hamilton Lugo Arellano   \n",
       "197                  August Archer   \n",
       "198                   Marlin Garza   \n",
       "199                 Leslie Sellers   \n",
       "\n",
       "                                                  pred  \n",
       "0    The first letter of each word in \"Morgan Calde...  \n",
       "1    The third letter of each word in Mervin Carrol...  \n",
       "2    The second letters of the words in Bert Schwar...  \n",
       "3    J K P R R are the first letters of each word i...  \n",
       "4    To find the answer, follow these steps:\\n\\n1. ...  \n",
       "..                                                 ...  \n",
       "195  The third letter of each word in Drew Vazquez ...  \n",
       "196  To find the answer, follow these steps:\\n\\n1. ...  \n",
       "197  The fourth letter of the word \"August\" is \"g\"....  \n",
       "198  The second letters of the words \"Marlin\" and \"...  \n",
       "199  The first letter of each word in Leslie Seller...  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/new_dataset/result_class_mis_letter_zero_val.csv\") as f:\n",
    "    suffixes = pd.read_csv(f)\n",
    "suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/new_dataset/result_class_mis_letter_zero_val.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/new_dataset/result_class_mis_letter_zero_val.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     suffixes \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(f)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# the control vector we're going to make is honest / untruthful, like the paper\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/representation/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/new_dataset/result_class_mis_letter_zero_val.csv'"
     ]
    }
   ],
   "source": [
    "with open(\"data/new_dataset/result_class_mis_letter_zero_val.csv\") as f:\n",
    "    suffixes = pd.read_csv(f)\n",
    "# the control vector we're going to make is honest / untruthful, like the paper\n",
    "positive_personas = [\"careful\"]\n",
    "negative_personas = [\"rough\"]\n",
    "def template(persona: str, suffix: str, prompt: str) -> str:\n",
    "    if persona==\"careful\":\n",
    "        result = f\"{user_tag} You are an attentive AI assistant. Please carefully answer the question and comprehensively check the each reasoning process. {prompt} {asst_tag} {suffix}\"\n",
    "    elif persona==\"rough\":\n",
    "        result = f\"{user_tag}You are a careless AI assistant.Please provide a response to the following question with complete randomness and full of loopholes  {prompt} {asst_tag} {suffix}\"\n",
    "    return result\n",
    "    \n",
    "dataset = []\n",
    "for index, suffix in suffixes.iterrows():\n",
    "    tokens = tokenizer.tokenize(suffix['pred'])\n",
    "    # we augment our short suffix list by taking lots of different truncations.\n",
    "    # we always chop off the last 5 tokens so the model has something to complete.\n",
    "    if suffix['class'] == 'Totally correct':\n",
    "        length = len(tokens) - 5\n",
    "    elif suffix['class'] == 'Method correct but process wrong':\n",
    "        length = 10\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    prompt = \"Q: Take the '{index}' letter of each word in '{question}' and concatenate them.\\nA: \".format(index=suffix['ordinal_index'], question=suffix['Content'])\n",
    "    for i in range(1, length):\n",
    "        truncated = tokenizer.convert_tokens_to_string(tokens[:i])\n",
    "        # print(truncated)\n",
    "        ntrain = 1024\n",
    "\n",
    "        for positive_persona, negative_persona in zip(positive_personas, negative_personas):\n",
    "            dataset.append(\n",
    "                DatasetEntry(\n",
    "                    positive=template(positive_persona, truncated, prompt=prompt),\n",
    "                    negative=template(negative_persona, truncated, prompt=prompt),\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2528"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个进度条用于前向传递，我们在其中收集隐藏状态，第二个进度条针对这些隐藏状态拟合层 PCA，总共仅一分多钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 158/158 [01:37<00:00,  1.62it/s]\n",
      "100%|██████████| 31/31 [00:21<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "model.reset() # make sure you always reset the model before training a new vector\n",
    "control_vector = ControlVector.train(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==baseline\n",
      "<s> [INST] Q: Take the 'third' letter of each word in 'Edwin Arias' and concatenate them.\n",
      "A:  [/INST] The third letter of each word in 'Edwin Arias' is:\n",
      "\n",
      "E (from Edwin)\n",
      " D (from Edwin)\n",
      " w (from Arias, as w is the third letter of the second syllable \"Ari\" in Arias)\n",
      "\n",
      "So, the concatenated third letters of each word in 'Edwin Arias' is 'ew'.</s>\n",
      "\n",
      "++control\n",
      "<s> [INST] Q: Take the 'third' letter of each word in 'Edwin Arias' and concatenate them.\n",
      "A:  [/INST] To complete the task, we need to identify the given name \"Edwin Arias\" and then find the instruction given in the problem statement, which is to find the \"third\" letter of each word and then concatenate the given instruction means to find the word given to us first and then find the word given to us second, and then we need to identify the instruction given to us in the problem statement which is to find the \"third\" letter of each word given to us in the problem statement.\n",
      "\n",
      "First, we need to identify the given name \"Edwin Arias\" and break it down into two given words \"Edwin\" and \"Arias\"\n",
      "\n",
      "Next, we need to identify the instruction given in the problem statement which is to find the \"third\" letter of each word given to us in the problem statement.\n",
      "\n",
      "To find the third letter of the given word \"Edwin\" we need to identify the given word \"Edwin\" and then identify the instruction given in the problem statement which is to find the \"third\" letter of the given word \"Edwin\"\n",
      "\n",
      "The given word \"Edwin\" is given to us in the problem statement and the instruction is to find the \"third\" letter of the given word \"Edwin\"\n",
      "\n",
      "To find the third letter of the given word \"Edwin\" we need to identify the given word \"Edwin\" and then identify the instruction given in the problem statement which is to find the \"third\" letter of the given word \"Edwin\"\n",
      "\n",
      "The given word \"Edwin\" is given to us in the problem statement and the instruction is to find the \"third\" letter of the given word \"Edwin\"\n",
      "\n",
      "To find the third letter of the given word \"Edwin\" we need to identify the given word \"Edwin\" and then identify the instruction given in the problem statement which is to find the \"third\" letter of the given word \"Edwin\"\n",
      "\n",
      "The given word \"Edwin\" is given to us in the problem statement and the instruction is to find the \"third\" letter of the given word \"Edwin\"\n",
      "\n",
      "To find the third letter of the given word \"Edwin\" we need to identify the given word \"Edwin\" and then identify the instruction given in the problem statement which is to find the \"third\" letter of the given word \"Edwin\"\n",
      "\n",
      "The given word \"Edwin\" is given to us in the problem statement and the instruction\n",
      "\n",
      "--control\n",
      "<s> [INST] Q: Take the 'third' letter of each word in 'Edwin Arias' and concatenate them.\n",
      "A:  [/INST] The third letters of each letter in 'Edwin Arias' are: d, a, i, n. Concatenated, they make an 'adnan' sequence. Please note that, as a third letter, the first 'a' comes from the first 'A' in 'Arias'.</s>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Q: Take the '{index}' letter of each word in '{question}' and concatenate them.\\nA: \".format(index='third', question='Edwin Arias')\n",
    "# this question is taken from the paper\n",
    "input = f\"{user_tag} {prompt} {asst_tag}\"\n",
    "# tokenizer and generation settings\n",
    "input_ids = tokenizer(input, return_tensors=\"pt\").to(model.device)\n",
    "settings = {\n",
    "    \"pad_token_id\": tokenizer.eos_token_id, # silence warning\n",
    "    \"do_sample\": False, # temperature=0\n",
    "    \"max_new_tokens\": 512,\n",
    "    # \"repetition_penalty\": 1.1, # reduce control jank\n",
    "}\n",
    "print(\"==baseline\")\n",
    "model.reset()\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "print(\"\\n++control\")\n",
    "# add the control vector with a certain strength (try increasing or decreasing this!)\n",
    "model.set_control(control_vector, 1)\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "print(\"\\n--control\")\n",
    "# subtract the control vector, giving the opposite result (e.g. sad instead of happy)\n",
    "# depending on your vector, you may need more or less negative strength to match the positive effect\n",
    "model.set_control(control_vector, -1)\n",
    "print(tokenizer.decode(model.generate(**input_ids, **settings).squeeze()))\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_ref",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
